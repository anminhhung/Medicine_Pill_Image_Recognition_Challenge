{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pipeline_Detectron2.ipynb",
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "background_execution": "on",
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Download data\n"
      ],
      "metadata": {
        "id": "5n2_Kj--hMdX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/anminhhung/vehicle_data"
      ],
      "metadata": {
        "id": "vitHPuwZhMMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup Detectron2"
      ],
      "metadata": {
        "id": "w8uO1ntbh_PP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cython pyyaml==5.1\n",
        "!python -m pip install torch==1.5.0+cu101 torchvision==0.6.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html && \\\n",
        "python -m pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.5/index.html"
      ],
      "metadata": {
        "id": "iBw73kWMjBtI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFkgjO40hCk6"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/facebookresearch/detectron2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd detectron2\n",
        "# !python -m pip install -e .\n",
        "# !python setup.py build develop\n",
        "# %cd .."
      ],
      "metadata": {
        "id": "Ppc9fNPiiEsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import package"
      ],
      "metadata": {
        "id": "RsroEE8Yjbbe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import json\n",
        "import random\n",
        "import itertools\n",
        "import torch\n",
        "import copy\n",
        "import numpy as np\n",
        "\n",
        "import detectron2\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultTrainer,  DefaultPredictor\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader, build_detection_train_loader\n",
        "from detectron2.structures import BoxMode\n",
        "from detectron2.data import detection_utils\n",
        "import detectron2.data.transforms as T\n",
        "\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "0M3etbM0jduJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert yolo -> json (detectron format)"
      ],
      "metadata": {
        "id": "9mjJODb4l2VK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data_dicts_mrcnn(img_dir):\n",
        "    anno_files = [f for f in os.listdir(img_dir) if f.split(\".\")[-1] != 'txt']\n",
        "    # print(\"anno_files: \", anno_files)\n",
        "    classes = ['0', '1', '2', '3', '4']\n",
        "\n",
        "    dataset_dicts = []\n",
        "    count = 0\n",
        "    fail_cnt = 0\n",
        "    for image_id, filename in enumerate(anno_files):\n",
        "      try:\n",
        "        record = {}\n",
        "        img_path = os.path.join(img_dir, filename)\n",
        "        # print(\"img_path: \", img_path)\n",
        "        height, width = cv2.imread(img_path).shape[:2]\n",
        "        \n",
        "        record[\"file_name\"] = img_path\n",
        "        record[\"image_id\"] = image_id\n",
        "        record[\"height\"] = height\n",
        "        record[\"width\"] = width\n",
        "\n",
        "        txt_path = filename.split(\".\")[0] + '.txt'\n",
        "        annotations = open(os.path.join(img_dir, txt_path), 'r')\n",
        "        objs = []\n",
        "        for line in annotations:\n",
        "          line = line.rstrip('\\n')\n",
        "          class_id, x_center, y_center, w, h = line.split()[:]\n",
        "          w = int(float(w) * width)\n",
        "          h = int(float(h) * height)\n",
        "          xmin = int((float(x_center) * width) - w/2)\n",
        "          ymin = int((float(y_center) * height) - h/2)\n",
        "          xmax = xmin + w\n",
        "          ymax = ymin + h\n",
        "\n",
        "          px = [xmin, xmax, xmax, xmin]\n",
        "          py = [ymin, ymin, ymax, ymax]\n",
        "\n",
        "          poly = [(x, y) for x, y in zip(px, py)]\n",
        "          poly = list(itertools.chain.from_iterable(poly))\n",
        "\n",
        "          obj = {\n",
        "                'bbox': [xmin, ymin, xmax, ymax],\n",
        "                'bbox_mode': BoxMode.XYXY_ABS,\n",
        "                'segmentation': [poly],\n",
        "                'category_id': int(class_id),\n",
        "                \"iscrowd\": 0\n",
        "          }\n",
        "          objs.append(obj)\n",
        "        record[\"annotations\"] = objs\n",
        "        dataset_dicts.append(record)\n",
        "        count += 1\n",
        "        # print(count)\n",
        "      except:\n",
        "        fail_cnt += 1\n",
        "        with open(\"fail_log.txt\", \"a+\") as f:\n",
        "          f.write(\"path image failed: {}\\n\".format(img_path))\n",
        "\n",
        "    # print(\"fail_cnt: \", fail_cnt)\n",
        "    return dataset_dicts"
      ],
      "metadata": {
        "id": "cQ_MRRu2l_uW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dicts = get_data_dicts_mrcnn('vehicle_data/train')\n",
        "val_dicts = get_data_dicts_mrcnn('vehicle_data/val')\n",
        "\n",
        "# write and save data \n",
        "with open('train_dicts_rcnn.json', 'w') as fp:\n",
        "    json.dump(train_dicts, fp)\n",
        "\n",
        "with open('val_dicts_rcnn.json', 'w') as fp:\n",
        "    json.dump(val_dicts, fp)"
      ],
      "metadata": {
        "id": "Z19ieYKFmYCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load json data, trainer"
      ],
      "metadata": {
        "id": "GJztOQPgrDZw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load json data\n",
        "with open('train_dicts_rcnn.json', 'r') as fp:\n",
        "    val_dicts = json.load(fp)\n",
        "\n",
        "with open('val_dicts_rcnn.json', 'r') as fp:\n",
        "    train_dicts = json.load(fp)"
      ],
      "metadata": {
        "id": "753gBt8OrEyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(val_dicts)):\n",
        "  for j in range(len(val_dicts[i][\"annotations\"])):\n",
        "      val_dicts[i][\"annotations\"][j]['bbox_mode'] = BoxMode.XYXY_ABS\n",
        "      \n",
        "for i in range(len(train_dicts)):\n",
        "  for j in range(len(train_dicts[i][\"annotations\"])):\n",
        "      train_dicts[i][\"annotations\"][j]['bbox_mode'] = BoxMode.XYXY_ABS"
      ],
      "metadata": {
        "id": "nAMm52HTreyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = ['0', '1', '2', '3', '4']\n",
        "data = [train_dicts, val_dicts]\n",
        "\n",
        "for index, d in enumerate([\"train\", \"val\"]):\n",
        "  DatasetCatalog.register(\"vehicle_data/\" + d, lambda index=index: data[index])\n",
        "  MetadataCatalog.get(\"vehicle_data/\" + d).set(thing_classes=classes)\n",
        "  \n",
        "vehicle_metadata = MetadataCatalog.get(\"vehicle_data/train\")"
      ],
      "metadata": {
        "id": "Y5jYGjJarhTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Without Augmentation\n",
        "class CustomTrainer(DefaultTrainer):\n",
        "  @classmethod\n",
        "  def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
        "\n",
        "    if output_folder is None:\n",
        "        os.makedirs(\"mask_rcnn_R_101_FPN_3x_new_train\", exist_ok=True) # name dir\n",
        "        output_folder = \"mask_rcnn_R_101_FPN_3x_new_train\"\n",
        "\n",
        "    return COCOEvaluator(dataset_name, cfg, False, output_folder)"
      ],
      "metadata": {
        "id": "hpb-MvLbrt-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_mapper(dataset_dict, size = (800,800), flip_prob = 0, min_brightness = 0.5, max_brightness = 1.5, \\\n",
        "                min_contrast = 0.5, max_contrast = 1.5, min_saturation = 0.5, max_saturation = 1.5):\n",
        "    # Implement a mapper, similar to the default DatasetMapper, but with your own customizations\n",
        "    dataset_dict = copy.deepcopy(dataset_dict)  # it will be modified by code below\n",
        "    image = detection_utils.read_image(dataset_dict[\"file_name\"], format=\"BGR\")\n",
        "    transform_list = [ \n",
        "                    T.Resize(size),\n",
        "                    T.RandomBrightness(min_brightness, max_brightness),\n",
        "                    T.RandomContrast(min_contrast, max_contrast),\n",
        "                    T.RandomSaturation(min_saturation, max_saturation),\n",
        "\n",
        "                    T.RandomFlip(prob=flip_prob, horizontal=False, vertical=True),\n",
        "                    T.RandomFlip(prob=flip_prob, horizontal=True, vertical=False), \n",
        "                ]\n",
        "    image, transforms = T.apply_transform_gens(transform_list, image)\n",
        "    dataset_dict[\"image\"] = torch.as_tensor(image.transpose(2, 0, 1).astype(\"float32\"))\n",
        "\n",
        "    annos = [\n",
        "        detection_utils.transform_instance_annotations(obj, transforms, image.shape[:2])\n",
        "        for obj in dataset_dict.pop(\"annotations\")\n",
        "        if obj.get(\"iscrowd\", 0) == 0\n",
        "    ]\n",
        "    instances = detection_utils.annotations_to_instances(annos, image.shape[:2])\n",
        "    dataset_dict[\"instances\"] = detection_utils.filter_empty_instances(instances)\n",
        "    return dataset_dict\n",
        "\n",
        "# Training with augmentation\n",
        "class AugmentTrainer(DefaultTrainer):\n",
        "    @classmethod\n",
        "    def build_train_loader(cls, cfg):\n",
        "        return build_detection_train_loader(cfg, mapper=custom_mapper)\n",
        "\n",
        "    @classmethod\n",
        "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
        "\n",
        "        if output_folder is None:\n",
        "            os.makedirs(\"Evaluate_dir\", exist_ok=True)\n",
        "            output_folder = \"Evaluate_dir\"\n",
        "\n",
        "        return COCOEvaluator(dataset_name, cfg, False, output_folder)"
      ],
      "metadata": {
        "id": "FLGOduUBr1zn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize data"
      ],
      "metadata": {
        "id": "5XizacgLr_vH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# dataset_dicts = get_license_plate_dicts('detectron2/datasets/license_plate_dataset/val')\n",
        "for d in random.sample(val_dicts, 10):\n",
        "    img = cv2.imread(d[\"file_name\"])\n",
        "    v = Visualizer(img[:, :, ::-1], metadata=vehicle_metadata, scale=0.5)\n",
        "    v = v.draw_dataset_dict(d)\n",
        "    plt.figure(figsize = (14, 10))\n",
        "    plt.imshow(cv2.cvtColor(v.get_image()[:, :, ::-1], cv2.COLOR_BGR2RGB))\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "a1HMFv7ssA-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "wf_sYzVKsl7D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(\"./detectron2/configs/COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\")\n",
        "cfg.DATASETS.TRAIN = (\"vehicle_data/train\",)\n",
        "cfg.DATASETS.TEST = (\"vehicle_data/val\",)   # no metrics implemented for this dataset\n",
        "cfg.DATALOADER.NUM_WORKERS = 4\n",
        "\n",
        "#https://github.com/facebookresearch/detectron2/blob/master/MODEL_ZOO.md\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
        "# cfg.MODEL.WEIGHTS = \"mask_rcnn_R_101_FPN_3x_model_new_train/model_final.pth\" # load saved model\n",
        "# cfg.MODEL.WEIGHTS = \"\" # without transfer learning\n",
        "\n",
        "cfg.SOLVER.IMS_PER_BATCH = 8\n",
        "cfg.SOLVER.BASE_LR = 0.00001\n",
        "cfg.SOLVER.MAX_ITER = 1000\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 32\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 7\n",
        "cfg.OUTPUT_DIR = \"./mask_rcnn_R_101_FPN_3x_model_new_train\"\n",
        "\n",
        "cfg.TEST.EVAL_PERIOD = 500 # eval for each 500 iters\n",
        "\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "trainer = CustomTrainer(cfg)\n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "YYCuNGOts2LR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict "
      ],
      "metadata": {
        "id": "0VeEfd_xS6KE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import json\n",
        "import time\n",
        "import random\n",
        "import itertools\n",
        "import numpy as np\n",
        "\n",
        "from detectron2.engine import DefaultTrainer, DefaultPredictor\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset, evaluator\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader\n",
        "from detectron2.structures import BoxMode\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import json\n",
        "\n",
        "def predict (path_weigths, path_config, confidence_threshold, num_of_class, path_img\n",
        "             \n",
        "             \n",
        "             ):\n",
        "  cfg = get_cfg()\n",
        "  cfg.merge_from_file(path_config)\n",
        "  cfg.MODEL.WEIGHTS = path_weigths\n",
        "\n",
        "  cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = confidence_threshold\n",
        "  cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 8   \n",
        "  cfg.MODEL.ROI_HEADS.NUM_CLASSES = num_of_class \n",
        "  predictor = DefaultPredictor(cfg)\n",
        "  im = cv2.imread(path_img)\n",
        "  outputs = predictor(im)\n",
        "\n",
        "  boxes = outputs[\"instances\"].pred_boxes \n",
        "  scores = outputs[\"instances\"].scores \n",
        "  classes = outputs[\"instances\"].pred_classes \n",
        "\n",
        "  list_bbox = []\n",
        "  for bbox in boxes:\n",
        "    list_tmp = []\n",
        "    for ele in bbox:\n",
        "      list_tmp.append(int(ele))\n",
        "    \n",
        "    list_bbox.append(list_tmp)\n",
        "  \n",
        "  list_classes = []\n",
        "  for my_cls in classes:\n",
        "    list_classes.append(classes_raw[my_cls])\n",
        "  \n",
        "  return outputs, list_bbox, scores, list_classes\n",
        "\n",
        "#Đầu vào detect = output của hàm predict, frame = original image của mình, classs = tên class để visualize\n",
        "def visualize (out, frame, classs):\n",
        "  boxes = out['instances'].pred_boxes\n",
        "  scores = out['instances'].scores\n",
        "  classes = out['instances'].pred_classes\n",
        "  for i in range (len(classes)):\n",
        "    if (scores[i] > 0.4):\n",
        "      for j in boxes[i]:\n",
        "        start = (int (j[0]), int (j[1]))\n",
        "        end = (int (j[2]), int (j[3]))\n",
        "        print (start)\n",
        "        print (end)\n",
        "        width =  end[0] - start[0]\n",
        "        height = end[1] - start[1]\n",
        "        print ('width:', width)\n",
        "        print ('height:', height)\n",
        "        print('class:', int (classes[i]))\n",
        "        print('score:', float (scores[i]))\n",
        "        print ('---------------------', start, end, scores[i], classes[i])\n",
        "      color = int (classes[i])\n",
        "      print (classes[i])\n",
        "        \n",
        "      cv2.rectangle(frame, start, end, (random.randint(0,255),random.randint(0,255),255), 1)\n",
        "      cv2.putText(frame, str (classs[color]),start, cv2.FONT_HERSHEY_PLAIN, 1, (random.randint(0,255),random.randint(0,255),255), 2)\n",
        "  return frame\n",
        "\n",
        "\n",
        "path_weigth = 'mask_rcnn_R_101_FPN_3x_model_new_train/model_final.pth'\n",
        "path_config = './detectron2/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml'\n",
        "confidences_threshold = 0.5\n",
        "num_of_class = 5\n",
        "path_img = 'vehicle_data/val/cam_01_0.jpg'\n",
        "classes_raw = ['0', '1', '2', '3', '4']\n",
        "\n",
        "outputs, boxes, scores, classes = predict(path_weigth, path_config, confidences_threshold, num_of_class, path_img)\n",
        "print(outputs)\n",
        "_frame = cv2.imread(path_img)\n",
        "frame = visualize (outputs, _frame, classes )\n",
        "cv2.imwrite(\"frame.jpg\", frame)\n",
        "cv2_imshow(frame)\n"
      ],
      "metadata": {
        "id": "JEC45B4AS7GA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}